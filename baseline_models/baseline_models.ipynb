{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "\n",
    "We evaluated four baseline models for our project: Logistic Regression, Support Vector Machine (SVM), Random Forest, and XGBoost.\n",
    "\n",
    "**Logistic Regression** serves as a simple, interpretable baseline to assess the linear separability of the data.  \n",
    "**Support Vector Machine (SVM)** is included for its robustness to noise and ability to model non-linear decision boundaries using kernel functions.  \n",
    "**Random Forest** and **XGBoost** are tree-based models that offer greater flexibility, are less sensitive to class imbalance, and provide transparency through feature importance analysis.\n",
    "\n",
    "To address class imbalance:  \n",
    "- We trained all baseline models on a SMOTEd version of the training data.  \n",
    "- Each model was evaluated using class-based metrics: **Precision**, **Recall**, and **F1 score**. Less focus was placed on **Accuracy**, as it may be misleading due to the class imbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv(\"../data/processed/train_set_SMOTEd.csv\")\n",
    "test_df = pd.read_csv(\"../data/processed/test_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "We encode the credit status variable, assigning `'Good' = 1` and `'Bad' = 0`.  \n",
    "A `MinMaxScaler` is applied to unscaled numerical features to normalize them to the [0, 1] range, ensuring compatibility with models sensitive to feature scales, such as Logistic Regression and SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns (all except 'id' and 'credit_status')\n",
    "feature_columns = [col for col in train_df.columns if col not in [\"credit_status\", \"id\"]]\n",
    "\n",
    "# Split features and target\n",
    "X_train = train_df[feature_columns]\n",
    "y_train = LabelEncoder().fit_transform(train_df[\"credit_status\"])\n",
    "X_test = test_df[feature_columns]\n",
    "y_test = LabelEncoder().fit_transform(test_df[\"credit_status\"])\n",
    "\n",
    "# Standardize features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  predicted_credit_status\n",
      "0  5052720                        0\n",
      "1  5087861                        1\n",
      "2  5068206                        0\n",
      "3  5137255                        0\n",
      "4  5023163                        1\n",
      "Accuracy: 0.5970927043335161\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 283  358]\n",
      " [2580 4071]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.44      0.16       641\n",
      "           1       0.92      0.61      0.73      6651\n",
      "\n",
      "    accuracy                           0.60      7292\n",
      "   macro avg       0.51      0.53      0.45      7292\n",
      "weighted avg       0.85      0.60      0.68      7292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42, class_weight=\"balanced\") #\n",
    "logreg.fit(X_train_scaled, y_train);\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "\n",
    "# Attach predictions to customer IDs\n",
    "results_df = test_df[[\"id\"]].copy()\n",
    "results_df[\"predicted_credit_status\"] = y_pred\n",
    "\n",
    "# Display results\n",
    "print(results_df.head())\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression (LR) model demonstrates strong **precision** on the majority class (Good credit), with a value of **0.92**, but its **recall** for the same class is lower, at **0.61**. On the minority class (Bad credit), the model performs poorly, with **precision** and **F1-score** at just **0.10** and **0.16**, respectively. This indicates that the model is only correctly identifying a small fraction of individuals with bad credit, which is a critical shortcoming for credit risk applications.\n",
    "\n",
    "These results suggest that the data is **not linearly separable**, and a linear model like logistic regression is insufficient to capture the underlying complexity. Non-linear models, such as **kernelized SVMs** or **tree-based models**, may be better suited to this task, as they can handle the intricacies of class imbalances and non-linearity more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We performed hyperparameter tuning for the SVM model, as its performance is highly sensitive to both the **kernel choice** and the **regularization parameter (C)**. These hyperparameters directly influence the model’s capacity to handle our non-linearly separable data:\n",
    "\n",
    "- The **kernel function** determines how the input space is transformed into a higher-dimensional feature space, enabling the SVM to learn non-linear decision boundaries.\n",
    "- The **regularization parameter (C)** controls the trade-off between maximizing the margin and minimizing classification error. A smaller C encourages a wider margin at the cost of some misclassifications, while a larger C prioritizes correct classification of training points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training SVM with kernel = 'linear'\n",
      " F1 Score (linear): 0.8178\n",
      "\n",
      " Training SVM with kernel = 'rbf'\n",
      " F1 Score (rbf): 0.6767\n",
      "\n",
      " Training SVM with kernel = 'poly'\n",
      " F1 Score (poly): 0.9406\n",
      "\n",
      " Training SVM with kernel = 'sigmoid'\n",
      " F1 Score (sigmoid): 0.9329\n",
      "\n",
      " F1 Score Comparison:\n",
      " - linear: 0.8178\n",
      " - rbf: 0.6767\n",
      " - poly: 0.9406\n",
      " - sigmoid: 0.9329\n"
     ]
    }
   ],
   "source": [
    "# Suppress ConvergenceWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# List of kernels to compare\n",
    "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "\n",
    "# Dictionary to store results\n",
    "f1_scores = {}\n",
    "\n",
    "# Train and evaluate SVM for each kernel\n",
    "for kernel in kernels:\n",
    "    print(f\" Training SVM with kernel = '{kernel}'\")\n",
    "    model = SVC(kernel=kernel, probability=False, random_state=42, max_iter=1000)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    f1_scores[kernel] = score\n",
    "    print(f\" F1 Score ({kernel}): {score:.4f}\\n\")\n",
    "\n",
    "# Summary\n",
    "print(\" F1 Score Comparison:\")\n",
    "for kernel, score in f1_scores.items():\n",
    "    print(f\" - {kernel}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polynomial kernel yielded the best performance based on F1 score, suggesting it may be better suited to the complexity of this dataset compared to the other kernels tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      " Best C: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate SVM with sigmoid kernel for each C value\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = SVC(kernel = 'poly', probability = False, random_state = 42, max_iter = 1000),\n",
    "    param_grid = param_grid,\n",
    "    cv = 3,\n",
    "    scoring = 'f1',\n",
    "    n_jobs = 2,\n",
    "    verbose = 2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(\" Best C:\", grid_search.best_params_['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the cross-validation results, we selected C = 0.01 to train our final SVM baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  predicted_credit_status\n",
      "0  5052720                        1\n",
      "1  5087861                        1\n",
      "2  5068206                        1\n",
      "3  5137255                        1\n",
      "4  5023163                        1\n",
      "Accuracy: 0.8432528798683488\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  46  595]\n",
      " [ 548 6103]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.07      0.07       641\n",
      "           1       0.91      0.92      0.91      6651\n",
      "\n",
      "    accuracy                           0.84      7292\n",
      "   macro avg       0.49      0.49      0.49      7292\n",
      "weighted avg       0.84      0.84      0.84      7292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train final SVM model using best C and kernel\n",
    "svm_final = SVC(kernel = 'poly', C = 0.01, random_state = 42, max_iter = 1000)\n",
    "svm_final.fit(X_train_scaled, y_train);\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = svm_final.predict(X_test_scaled)\n",
    "\n",
    "# Attach predictions to customer IDs\n",
    "results_df = test_df[[\"id\"]].copy()\n",
    "results_df[\"predicted_credit_status\"] = y_pred\n",
    "\n",
    "# Display results\n",
    "print(results_df.head())\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicted nearly all instances as class 1 (Good credit), with a **precision of 0.91** and **recall of 0.92** for that class. In contrast, the minority class (Bad credit) was poorly classified, with a **precision of 0.08** and a **recall of 0.07**. \n",
    "\n",
    "These results indicate that the polynomial kernel was not effective in capturing the underlying structure of the data — particularly for the minority class. Despite having tested various kernel types and performing a grid search over the regularization parameter \\(C\\), the SVM continues to underperform on class 0.\n",
    "\n",
    "This reinforces the need for more effective handling of class imbalance via alternative model architectures, such as tree-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  predicted_credit_status\n",
      "0  5052720                        1\n",
      "1  5087861                        1\n",
      "2  5068206                        1\n",
      "3  5137255                        1\n",
      "4  5023163                        1\n",
      "Accuracy: 0.8712287438288535\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 238  403]\n",
      " [ 536 6115]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.37      0.34       641\n",
      "           1       0.94      0.92      0.93      6651\n",
      "\n",
      "    accuracy                           0.87      7292\n",
      "   macro avg       0.62      0.65      0.63      7292\n",
      "weighted avg       0.88      0.87      0.88      7292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Building the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "rf.fit(X_train, y_train);\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred = rf.predict(X_test)\n",
    "# Attach predictions to customer IDs\n",
    "results_df = test_df[[\"id\"]].copy()\n",
    "results_df[\"predicted_credit_status\"] = y_pred\n",
    "\n",
    "# Display results\n",
    "print(results_df.head())\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model attained a **precision of 0.31** and **recall of 0.37** for class 0, resulting in a **F1-score of 0.34**. While performance on the minority class is still limited, it marks a notable improvement over the linear and SVM models. For class 1 (Good credit), the model maintained high performance, with an F1-score of 0.93.\n",
    "\n",
    "These results indicate that the Random Forest model is better able to handle the non-linear relationships and class imbalance, making it a more effective baseline than linear classifiers in this context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  predicted_credit_status\n",
      "0  5052720                        1\n",
      "1  5087861                        1\n",
      "2  5068206                        1\n",
      "3  5137255                        1\n",
      "4  5023163                        1\n",
      "Accuracy: 0.8690345584201865\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 143  498]\n",
      " [ 457 6194]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.22      0.23       641\n",
      "           1       0.93      0.93      0.93      6651\n",
      "\n",
      "    accuracy                           0.87      7292\n",
      "   macro avg       0.58      0.58      0.58      7292\n",
      "weighted avg       0.87      0.87      0.87      7292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train XGBoost classifier\n",
    "xgb_model = XGBClassifier(eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train);\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Attach predictions to customer IDs\n",
    "results_df = test_df[[\"id\"]].copy()\n",
    "results_df[\"predicted_credit_status\"] = y_pred\n",
    "\n",
    "# Display results\n",
    "print(results_df.head())\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost model also demonstrates strong performance on the majority class (Good credit), with a **precision**, **recall**, and **F1-score** of **0.93**.\n",
    "\n",
    "For the minority class (Bad credit), XGBoost underperformed compared to Random Forest, with a **recall of 0.22** and **F1-score of 0.23**. While this marks a decline from Random Forest, it still represents a substantial improvement over the linear models (Logistic Regression and SVM), which struggled to detect class 0 almost entirely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
