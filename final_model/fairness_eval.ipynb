{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd227ce",
   "metadata": {},
   "source": [
    "# Fairness Evaluation\n",
    "\n",
    "Beyond predicting credit labels accurately, our project aims to develop a **fair and responsible model**. To this end, we adopted the **FEAT framework** — *Fairness, Ethics, Accountability, and Transparency* — which is widely used in the financial sector to guide responsible AI practices.\n",
    "\n",
    "We focused on two key **sensitive attributes**: `gender` and `age`. Since both features were ranked highly in our feature importance analysis, we chose not to remove them prematurely. Instead, we conducted a post-modeling fairness evaluation to assess potential bias.\n",
    "\n",
    "Fairness Metrics Used\n",
    "- **Equal Opportunity Difference (EOD):**  \n",
    "  Measures whether individuals who *truly qualify* (i.e., should receive a positive outcome) have equal chances of being correctly classified across demographic groups. This focuses on **true positive rates**.\n",
    "\n",
    "- **Demographic Parity Difference (DPD):**  \n",
    "  Assesses the **difference in positive prediction rates** between groups, regardless of their actual qualification.\n",
    "\n",
    "By comparing these fairness-specific metrics across subgroups, we aim to uncover any disparities in model behavior that could disproportionately affect certain demographic groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864fd578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import *\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_df = pd.read_csv(\"test_set_with_predictions.csv\")\n",
    "y_test_binary = test_df['credit_status']\n",
    "y_pred_custom = test_df['predicted_credit_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5498b6",
   "metadata": {},
   "source": [
    "We grouped `age` into three brackets based on life stages:  \n",
    "- **<35**: young adults or individuals early in their careers  \n",
    "- **35–50**: those likely to be in stable employment or supporting families  \n",
    "- **>50**: individuals approaching retirement  \n",
    "\n",
    "`Gender` was categorized as **male** or **female**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2a271a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Fairness Metrics by Gender:\n",
      "- Demographic Parity Difference: 0.0020\n",
      "- Equalized Odds Difference: 0.0057\n",
      "\n",
      "Random Forest Fairness Metrics by Age Group:\n",
      "- Demographic Parity Difference: 0.0566\n",
      "- Equalized Odds Difference: 0.0573\n"
     ]
    }
   ],
   "source": [
    "# Creating the 'age_bin' column with the adjusted bins for scaled age\n",
    "test_df['age_bin'] = pd.cut(\n",
    "    test_df['age'],  \n",
    "    bins=[0, 0.306122, 0.612244, 1],  # Adjusted bins for scaled age (corresponding to original age ranges)\n",
    "    labels=['<35', '35-50', '>50'],\n",
    "    right=False  # Right edge is excluded, i.e., <30 will not include 30\n",
    ")\n",
    "\n",
    "# Fairness metrics by gender\n",
    "dpd_rf_gender = demographic_parity_difference(y_test_binary, y_pred_custom, sensitive_features=test_df['gender'])\n",
    "eod_rf_gender = equalized_odds_difference(y_test_binary, y_pred_custom, sensitive_features=test_df['gender'])\n",
    "\n",
    "print(\"Random Forest Fairness Metrics by Gender:\")\n",
    "print(f\"- Demographic Parity Difference: {dpd_rf_gender:.4f}\")\n",
    "print(f\"- Equalized Odds Difference: {eod_rf_gender:.4f}\")\n",
    "\n",
    "# Fairness metrics by age group\n",
    "dpd_rf_age = demographic_parity_difference(y_test_binary, y_pred_custom, sensitive_features=test_df['age_bin'])\n",
    "eod_rf_age = equalized_odds_difference(y_test_binary, y_pred_custom, sensitive_features=test_df['age_bin'])\n",
    "\n",
    "print(\"\\nRandom Forest Fairness Metrics by Age Group:\")\n",
    "print(f\"- Demographic Parity Difference: {dpd_rf_age:.4f}\")\n",
    "print(f\"- Equalized Odds Difference: {eod_rf_age:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f632cc4",
   "metadata": {},
   "source": [
    "The values are all **close to zero**, indicating that the model does **not exhibit significant bias** toward any particular demographic group — even though age and gender were among the top predictors.  \n",
    "\n",
    "These findings suggest that our model is **fair** and does not **systematically disadvantage applicants** based on age or gender."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
